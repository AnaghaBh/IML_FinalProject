{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message data =  12.0\n",
      "Encrypted data =  3.0\n",
      "Original Message Sent =  12.0\n",
      "WARNING:tensorflow:From c:\\Users\\Anagha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Index(['author', 'comment', 'published_at', 'cleaned_comment',\n",
      "       'Sentiment_Num'],\n",
      "      dtype='object')\n",
      "Unique labels (after cleaning): [2 4 1 0 3]\n",
      "Label data type: int32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4685a5a30844fc89a0f82717383263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset labels: [4, 2, 2, 0, 1, 3, 2, 4, 2, 2, 2, 4, 2, 0, 1, 2, 3, 2, 3, 1, 1, 4, 0, 2, 0, 0, 3, 4, 2, 0, 0, 4, 0, 2, 3, 1, 4, 2, 2, 4, 4, 2, 2, 2, 2, 0, 2, 1, 4, 3, 4, 3, 3, 3, 2, 0, 4, 4, 4, 2, 2, 3, 2, 0, 2, 2, 0, 4, 2, 2, 3, 2, 4, 3, 4, 0, 2, 2, 2, 2, 4, 2, 2, 3, 3, 4, 0, 2, 4, 3, 2, 0, 2, 2, 1, 4, 4, 3, 0, 2, 2, 0, 2, 4, 2, 2, 4, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 4, 2, 0, 2, 2, 0, 4, 2, 4, 2, 2, 2, 3, 3, 2, 3, 2, 2, 4, 2, 0, 2, 2, 2, 2, 2, 1, 2, 4, 2, 2, 2, 2, 1, 4, 2, 2, 3, 0, 2, 2, 3, 2, 2, 2, 4, 3, 2, 0, 4, 0, 2, 3, 2, 4, 3, 4, 2, 2, 2, 4, 2, 2, 3, 0, 0, 4, 4, 3, 4, 2, 2, 2, 3, 2, 0, 0, 0, 2, 0, 2, 2, 1, 4, 2, 0, 4, 2, 2, 3, 0, 0, 3, 2, 0, 2, 3, 4, 4, 1, 0, 2, 0, 2, 0, 0, 2, 0, 1, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 0, 0, 3, 4, 2, 2, 0, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 0, 2, 2, 2, 1, 2, 3, 2, 1, 2, 3, 4, 3, 4, 2, 3, 4, 2, 0, 2, 4, 1, 2, 0, 2, 4, 2, 2, 0, 4, 2, 2, 0, 1, 2, 0, 2, 2, 3, 3, 2, 2, 2, 0, 2, 2, 4, 2, 2, 3, 4, 2, 2, 2, 2, 2, 1, 2, 2, 0, 4, 0, 2, 2, 3, 2, 2, 2, 2, 4, 3, 0, 2, 2, 4, 2, 1, 0, 2, 2, 2, 4, 3, 3, 2, 0, 4, 1, 2, 0, 2, 2, 3, 2, 2, 0, 2, 1, 0, 1, 3, 2, 0, 2, 3, 4, 4, 0, 4, 2, 4, 2, 0, 3, 2, 0, 3, 4, 2, 1, 3, 1, 3, 3, 2, 3, 0, 2, 2, 2, 3, 2, 0, 0, 4, 0, 1, 2, 2, 4, 1, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 4, 4, 0, 1, 2, 0, 2, 4, 2, 2, 3, 3, 2, 2, 4, 3, 2, 1, 2, 4, 3, 0, 3, 3, 2, 2, 0, 4, 2, 3, 2, 4, 0, 2, 0, 3, 2, 2, 0, 3, 4, 3, 2, 2, 0, 4, 2, 0, 0, 2, 0, 0, 1, 0, 2, 0, 2, 3, 0, 2, 0, 2, 2, 1, 2, 2, 2, 3, 4, 1, 1, 3, 2, 2, 2, 2, 2, 2, 0, 3, 2, 4, 2, 2, 2, 2, 2, 0, 1, 2, 2, 4, 0, 0, 0, 3, 2, 2, 2, 3, 0, 2, 4, 3, 2, 4, 0, 4, 2, 2, 0, 0, 1, 2, 2, 2, 3, 4, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 4, 2, 1, 2, 0, 3, 4, 2, 0, 3, 2, 1, 2, 2, 3, 0, 0, 4, 0, 1, 2, 2, 2, 3, 2, 2, 2, 3, 4]\n",
      "Test dataset labels: [0, 1, 2, 4, 3, 2, 2, 2, 0, 1, 0, 2, 3, 4, 2, 0, 2, 1, 4, 2, 4, 0, 2, 2, 4, 0, 2, 2, 2, 1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Anagha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anagha\\AppData\\Local\\Temp\\ipykernel_11088\\144760161.py:98: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572fe4035eb84d288c1ff51b15943742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4589, 'grad_norm': 5.761514186859131, 'learning_rate': 4.5370370370370374e-05, 'epoch': 0.28}\n",
      "{'loss': 1.4166, 'grad_norm': 5.267098426818848, 'learning_rate': 4.074074074074074e-05, 'epoch': 0.56}\n",
      "{'loss': 1.3556, 'grad_norm': 7.86448335647583, 'learning_rate': 3.611111111111111e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adbbf872a584cd7939e5e7bdac8c77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3161087036132812, 'eval_accuracy': 0.4838709677419355, 'eval_runtime': 18.1827, 'eval_samples_per_second': 1.705, 'eval_steps_per_second': 0.11, 'epoch': 1.0}\n",
      "{'loss': 1.2809, 'grad_norm': 6.580168724060059, 'learning_rate': 3.148148148148148e-05, 'epoch': 1.11}\n",
      "{'loss': 1.1678, 'grad_norm': 8.32638931274414, 'learning_rate': 2.6851851851851855e-05, 'epoch': 1.39}\n",
      "{'loss': 1.0223, 'grad_norm': 6.178020477294922, 'learning_rate': 2.2222222222222223e-05, 'epoch': 1.67}\n",
      "{'loss': 1.1319, 'grad_norm': 12.6719331741333, 'learning_rate': 1.7592592592592595e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0330a675e144e6eb9a62c2b1b800673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1971118450164795, 'eval_accuracy': 0.6129032258064516, 'eval_runtime': 18.3448, 'eval_samples_per_second': 1.69, 'eval_steps_per_second': 0.109, 'epoch': 2.0}\n",
      "{'loss': 0.9895, 'grad_norm': 7.925891399383545, 'learning_rate': 1.2962962962962962e-05, 'epoch': 2.22}\n",
      "{'loss': 0.8399, 'grad_norm': 6.837340831756592, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n",
      "{'loss': 0.857, 'grad_norm': 7.451780796051025, 'learning_rate': 3.7037037037037037e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e6202523b94519b85eb51acab97748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2050241231918335, 'eval_accuracy': 0.6129032258064516, 'eval_runtime': 20.5858, 'eval_samples_per_second': 1.506, 'eval_steps_per_second': 0.097, 'epoch': 3.0}\n",
      "{'train_runtime': 6285.3871, 'train_samples_per_second': 0.274, 'train_steps_per_second': 0.017, 'train_loss': 1.1221024107050013, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f226349b8d4c3f832280442f4adf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anagha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anagha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anagha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         6\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.72      0.93      0.81        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.40      0.40      0.40         5\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.32      0.40      0.36        31\n",
      "weighted avg       0.49      0.61      0.54        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Loading the Dataset from Excel\n",
    "file_path = \"C:/Users/Anagha/IML_FinalProject/Training_data_Comments.xlsx\"  \n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Print the columns of the DataFrame to understand its structure\n",
    "print(df.columns)\n",
    "\n",
    "\n",
    "# Ensure the dataset has 'text' and 'label' columns\n",
    "df = df.rename(columns={\"cleaned_comment\": \"text\", \"Sentiment_Num\": \"label\"})\n",
    "\n",
    "# Drop rows where 'text' or 'label' are missing\n",
    "df = df.dropna(subset=[\"text\", \"label\"])\n",
    "\n",
    "# Remove rows with non-finite values in 'label'\n",
    "df = df[df[\"label\"].apply(lambda x: np.isfinite(x))]\n",
    "\n",
    "# Convert 'label' from float to integer type\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "# Check unique labels and data type\n",
    "print(\"Unique labels (after cleaning):\", df[\"label\"].unique())\n",
    "print(\"Label data type:\", df[\"label\"].dtype)\n",
    "\n",
    "# Convert the cleaned DataFrame to a Hugging Face Dataset format\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Tokenize the Dataset\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply the tokenization function to the dataset in batches\n",
    "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
    "\n",
    "# Split the dataset into training and testing sets (Training on 95% of data, testing later on a new file)\n",
    "split = tokenized_dataset.train_test_split(test_size=0.05)\n",
    "train_dataset = split[\"train\"]\n",
    "test_dataset = split[\"test\"]\n",
    "\n",
    "\n",
    "print(\"Train dataset labels:\", train_dataset[\"label\"])\n",
    "print(\"Test dataset labels:\", test_dataset[\"label\"])\n",
    "\n",
    "# Remove unnecessary columns from the datasets to keep only the required data\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "\n",
    "# Load the Pre-trained Model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=df[\"label\"].nunique())\n",
    "\n",
    "# Define Training Arguments and # Set up the training parameters\n",
    "training_args = TrainingArguments(\n",
    "    # Where to save model outputs and checkpoints\n",
    "    output_dir=\"./results\",\n",
    "    # Check model performance at the end of each training cycle\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # Save the model after each training cycle\n",
    "    save_strategy=\"epoch\",\n",
    "    # How fast the model learns\n",
    "    learning_rate=5e-5,\n",
    "    # Number of samples processed at once during training\n",
    "    per_device_train_batch_size=16,\n",
    "    # Number of samples processed at once during evaluation\n",
    "    per_device_eval_batch_size=16,\n",
    "    # Total number of times the model will see the training data\n",
    "    num_train_epochs=3,\n",
    "    # Regularization to prevent overfitting\n",
    "    weight_decay=0.01,\n",
    "    # Where to save logs of training progress\n",
    "    logging_dir=\"./logs\",\n",
    "    # How often to log training metrics\n",
    "    logging_steps=10,\n",
    "    # Use the best model found during training at the end\n",
    "    load_best_model_at_end=True,\n",
    "    # Metric used to determine the best model\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "# Function to compute evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    # Unpack predictions and true labels\n",
    "    logits, labels = eval_pred\n",
    "    # Get predicted class indices\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    # Calculate accuracy\n",
    "    return {\"accuracy\": (preds == labels).mean()}\n",
    "\n",
    "# Create a Trainer instance with the model, training settings, datasets, and metric function\n",
    "trainer = Trainer(\n",
    "    # The model to train\n",
    "    model=model,\n",
    "    # Training settings\n",
    "    args=training_args,\n",
    "    # Training data\n",
    "    train_dataset=train_dataset,\n",
    "    # Evaluation data\n",
    "    eval_dataset=test_dataset,\n",
    "    # Tokenizer for processing text\n",
    "    tokenizer=tokenizer,\n",
    "    # Function to calculate metrics\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Training the Model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluating the Model\n",
    "# Get predictions for the test data\n",
    "predictions = trainer.predict(test_dataset)\n",
    "# Determine predicted classes\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "print(\"Evaluation Metrics:\\n\", classification_report(test_dataset[\"label\"], preds))\n",
    "\n",
    "# Save the trained model and tokenizer for later use\n",
    "model.save_pretrained(\"fine_tuned_bert\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_bert\")\n",
    "\n",
    "# Using the Fine-Tuned Model for Inference\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create a sentiment analysis pipeline with the fine-tuned model\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"fine_tuned_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             author                                            comment  \\\n",
      "0     @guardiannews  For more context on this video:<br><a href=\"ht...   \n",
      "1    @AndrejWatches  First time i see this.<br>Not buying gillette ...   \n",
      "2      @user-rx162r                                               Hate   \n",
      "3        @apall2764  Ah sh..., after 30 years of Gillette I need to...   \n",
      "4  @yakovrokhlin316  I am done with Gillette razors. Switching to a...   \n",
      "\n",
      "           published_at                                               text  \\\n",
      "0  2019-01-21T11:04:16Z                     for more context on this video   \n",
      "1  2024-12-01T00:18:53Z  first time i see thisnot buying gillette ever ...   \n",
      "2  2024-11-30T04:45:19Z                                               hate   \n",
      "3  2024-11-29T14:15:02Z  ah sh after 30 years of gillette i need to fin...   \n",
      "4  2024-11-29T12:56:26Z  i am done with gillette razors switching to an...   \n",
      "\n",
      "  predicted_label  \n",
      "0         LABEL_0  \n",
      "1         LABEL_2  \n",
      "2         LABEL_0  \n",
      "3         LABEL_2  \n",
      "4         LABEL_2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments,pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer that were saved earlier\n",
    "model_path = \"fine_tuned_bert\"  # Path to the saved fine-tuned model\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load the New XLSX File with the actual testing data\n",
    "new_file_path = \"C:/Users/Anagha/IML_FinalProject/Youtube_Cleaned_Comments.xlsx\"  \n",
    "new_df = pd.read_excel(new_file_path)\n",
    "\n",
    "# Ensure the DataFrame Has a 'text' Column\n",
    "new_df = new_df.rename(columns={\"cleaned_comment\": \"text\"})\n",
    "\n",
    "# Drop rows where 'text' is missing\n",
    "new_df = new_df.dropna(subset=[\"text\"])\n",
    "\n",
    "# Using the Sentiment Pipeline for Predictions\n",
    "# Create a sentiment analysis pipeline using the fine-tuned model and tokenizer\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    truncation=True,  # Add truncation to handle long sequences\n",
    "    max_length=512,   # Set the maximum length of input sequences(BERT Requirement)\n",
    ")\n",
    "\n",
    "#Function to split long comments into smaller chunks\n",
    "def split_long_comments(text, max_length=512):\n",
    "    #Splits long text into chunks smaller than max_length tokens.\n",
    "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
    "    chunks = [tokens[i:i + max_length] for i in range(0, len(tokens), max_length)]\n",
    "    return [tokenizer.decode(chunk, skip_special_tokens=True) for chunk in chunks]\n",
    "\n",
    "# Apply splitting to long comments \n",
    "new_comments = new_df[\"text\"].tolist()  # Convert the 'text' column to a list\n",
    "# Convert the 'text' column to a list\n",
    "processed_comments = []\n",
    "# Check if comment exceeds the token limit\n",
    "for comment in new_comments:\n",
    "    if len(tokenizer(comment)[\"input_ids\"]) > 512:  \n",
    "        processed_comments.extend(split_long_comments(comment))  # Split long comments\n",
    "    else:\n",
    "        processed_comments.append(comment)  # Add short comments as is\n",
    "\n",
    "# Get the sentiment predictions for the processed comments\n",
    "results = sentiment_pipeline(processed_comments)\n",
    "\n",
    "# Map results back to the original DataFrame\n",
    "# Create a list to store predicted labels for each comment\n",
    "predicted_labels = []\n",
    "# Track the current index in the results list\n",
    "current_index = 0\n",
    "\n",
    "# Loop through each original comment to assign predictions\n",
    "for comment in new_comments:\n",
    "    if len(tokenizer(comment)[\"input_ids\"]) > 512:\n",
    "        split_chunks = split_long_comments(comment)\n",
    "        # Get the predictions for these chunks from the results\n",
    "        chunk_predictions = results[current_index:current_index + len(split_chunks)]\n",
    "        # Combine chunk predictions \n",
    "        # Use majority voting to determine the final label for the long comment\n",
    "        # Count occurrences of each label\n",
    "        combined_label = max(set([pred[\"label\"] for pred in chunk_predictions]), key=lambda x: [pred[\"label\"] for pred in chunk_predictions].count(x))\n",
    "        # Add the combined label to the predicted labels list\n",
    "        predicted_labels.append(combined_label)\n",
    "        current_index += len(split_chunks)\n",
    "    else:\n",
    "        predicted_labels.append(results[current_index][\"label\"])\n",
    "        current_index += 1\n",
    "\n",
    "# Add the predicted labels as a new column in the DataFrame\n",
    "new_df[\"predicted_label\"] = predicted_labels\n",
    "\n",
    "#Saving the Results to a New Excel File\n",
    "output_file_path = \"C:/Users/Anagha/IML_FinalProject/Test_Data_Prediction.xlsx\"  # Replace with desired output file path\n",
    "new_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Print a preview of the DataFrame\n",
    "print(new_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
